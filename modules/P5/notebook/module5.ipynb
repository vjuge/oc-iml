{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# P5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "docs = pd.read_csv(\"QueryResults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to convert a Decimal to a Double in C#?</td>\n",
       "      <td>&lt;p&gt;I want to use a &lt;code&gt;Track-Bar&lt;/code&gt; to c...</td>\n",
       "      <td>&lt;c#&gt;&lt;floating-point&gt;&lt;type-conversion&gt;&lt;double&gt;&lt;...</td>\n",
       "      <td>759</td>\n",
       "      <td>64063</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Calculate relative time in C#</td>\n",
       "      <td>&lt;p&gt;Given a specific &lt;code&gt;DateTime&lt;/code&gt; valu...</td>\n",
       "      <td>&lt;c#&gt;&lt;datetime&gt;&lt;time&gt;&lt;datediff&gt;&lt;relative-time-s...</td>\n",
       "      <td>1612</td>\n",
       "      <td>188799</td>\n",
       "      <td>552</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Determine a user's timezone</td>\n",
       "      <td>&lt;p&gt;Is there a standard way for a web server to...</td>\n",
       "      <td>&lt;html&gt;&lt;browser&gt;&lt;timezone&gt;&lt;user-agent&gt;&lt;timezone...</td>\n",
       "      <td>673</td>\n",
       "      <td>248432</td>\n",
       "      <td>157</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the fastest way to get the value of π?</td>\n",
       "      <td>&lt;p&gt;I'm looking for the fastest way to obtain t...</td>\n",
       "      <td>&lt;performance&gt;&lt;algorithm&gt;&lt;language-agnostic&gt;&lt;un...</td>\n",
       "      <td>341</td>\n",
       "      <td>63943</td>\n",
       "      <td>86</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Is gettimeofday() guaranteed to be of microsec...</td>\n",
       "      <td>&lt;p&gt;I am porting a game, that was originally wr...</td>\n",
       "      <td>&lt;linux&gt;&lt;winapi&gt;&lt;visual-c++&gt;&lt;unix&gt;&lt;timer&gt;</td>\n",
       "      <td>104</td>\n",
       "      <td>43767</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69729326</th>\n",
       "      <td>Endless sine generation in C</td>\n",
       "      <td>&lt;p&gt;I am working on a project which incorporate...</td>\n",
       "      <td>&lt;c&gt;&lt;performance&gt;&lt;time&gt;&lt;precision&gt;&lt;trigonometry&gt;</td>\n",
       "      <td>91</td>\n",
       "      <td>10074</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69832748</th>\n",
       "      <td>Error \"Error: A &lt;Route&gt; is only ever to be use...</td>\n",
       "      <td>&lt;p&gt;I am trying to use routing for the first ti...</td>\n",
       "      <td>&lt;javascript&gt;&lt;node.js&gt;&lt;reactjs&gt;&lt;frameworks&gt;&lt;rea...</td>\n",
       "      <td>57</td>\n",
       "      <td>77406</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69875125</th>\n",
       "      <td>find_element_by_* commands are deprecated in s...</td>\n",
       "      <td>&lt;p&gt;When starting the function&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;...</td>\n",
       "      <td>&lt;python&gt;&lt;selenium&gt;&lt;selenium-webdriver&gt;&lt;webdriv...</td>\n",
       "      <td>52</td>\n",
       "      <td>59346</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70358643</th>\n",
       "      <td>\"You are running create-react-app 4.0.3 which ...</td>\n",
       "      <td>&lt;p&gt;I got an error while creating a React appli...</td>\n",
       "      <td>&lt;javascript&gt;&lt;reactjs&gt;&lt;npm-install&gt;&lt;yarnpkg&gt;&lt;npx&gt;</td>\n",
       "      <td>167</td>\n",
       "      <td>76256</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70926799</th>\n",
       "      <td>CentOS through a VM - no URLs in mirrorlist</td>\n",
       "      <td>&lt;p&gt;I am trying to run a &lt;a href=\"https://en.wi...</td>\n",
       "      <td>&lt;linux&gt;&lt;centos&gt;&lt;vagrant&gt;&lt;virtualbox&gt;&lt;redhat&gt;</td>\n",
       "      <td>49</td>\n",
       "      <td>48154</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27128 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Title  \\\n",
       "Id                                                            \n",
       "4               How to convert a Decimal to a Double in C#?   \n",
       "11                            Calculate relative time in C#   \n",
       "13                              Determine a user's timezone   \n",
       "19           What is the fastest way to get the value of π?   \n",
       "88        Is gettimeofday() guaranteed to be of microsec...   \n",
       "...                                                     ...   \n",
       "69729326                       Endless sine generation in C   \n",
       "69832748  Error \"Error: A <Route> is only ever to be use...   \n",
       "69875125  find_element_by_* commands are deprecated in s...   \n",
       "70358643  \"You are running create-react-app 4.0.3 which ...   \n",
       "70926799        CentOS through a VM - no URLs in mirrorlist   \n",
       "\n",
       "                                                       Body  \\\n",
       "Id                                                            \n",
       "4         <p>I want to use a <code>Track-Bar</code> to c...   \n",
       "11        <p>Given a specific <code>DateTime</code> valu...   \n",
       "13        <p>Is there a standard way for a web server to...   \n",
       "19        <p>I'm looking for the fastest way to obtain t...   \n",
       "88        <p>I am porting a game, that was originally wr...   \n",
       "...                                                     ...   \n",
       "69729326  <p>I am working on a project which incorporate...   \n",
       "69832748  <p>I am trying to use routing for the first ti...   \n",
       "69875125  <p>When starting the function</p>\\n<pre><code>...   \n",
       "70358643  <p>I got an error while creating a React appli...   \n",
       "70926799  <p>I am trying to run a <a href=\"https://en.wi...   \n",
       "\n",
       "                                                       Tags  Score  ViewCount  \\\n",
       "Id                                                                              \n",
       "4         <c#><floating-point><type-conversion><double><...    759      64063   \n",
       "11        <c#><datetime><time><datediff><relative-time-s...   1612     188799   \n",
       "13        <html><browser><timezone><user-agent><timezone...    673     248432   \n",
       "19        <performance><algorithm><language-agnostic><un...    341      63943   \n",
       "88                 <linux><winapi><visual-c++><unix><timer>    104      43767   \n",
       "...                                                     ...    ...        ...   \n",
       "69729326    <c><performance><time><precision><trigonometry>     91      10074   \n",
       "69832748  <javascript><node.js><reactjs><frameworks><rea...     57      77406   \n",
       "69875125  <python><selenium><selenium-webdriver><webdriv...     52      59346   \n",
       "70358643   <javascript><reactjs><npm-install><yarnpkg><npx>    167      76256   \n",
       "70926799       <linux><centos><vagrant><virtualbox><redhat>     49      48154   \n",
       "\n",
       "          FavoriteCount  AnswerCount  \n",
       "Id                                    \n",
       "4                    58           12  \n",
       "11                  552           41  \n",
       "13                  157           27  \n",
       "19                   86           23  \n",
       "88                   19           10  \n",
       "...                 ...          ...  \n",
       "69729326             25           12  \n",
       "69832748             13           14  \n",
       "69875125             25            3  \n",
       "70358643             35            6  \n",
       "70926799             20            2  \n",
       "\n",
       "[27128 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.set_index('Id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs.drop(['Id', 'Score', 'ViewCount', 'FavoriteCount','AnswerCount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tags preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize the tags\n",
    "def tokenizeTags(tags):\n",
    "    \"\"\"\n",
    "    Remove some unwanted characters\n",
    "    \"\"\"\n",
    "    tags = tags.replace('<', ' ')\n",
    "    tags = tags.replace('>', '')\n",
    "    return tags.strip().split(' ')\n",
    "\n",
    "docs['Tags'] = docs['Tags'].apply(tokenizeTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['javascript', 'geolocation', 'projection', 'processing.js', 'proj4js']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one doc tags sample\n",
    "docs['Tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>apache-spark-sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>encryption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>configuration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>dom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "3054              java\n",
       "3025            python\n",
       "2695        javascript\n",
       "2644                c#\n",
       "2391               ios\n",
       "...                ...\n",
       "99        architecture\n",
       "99    apache-spark-sql\n",
       "98          encryption\n",
       "98       configuration\n",
       "98                 dom\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 200 most frequent tags\n",
    "all_tags = [item for sublist in docs['Tags'] for item in sublist]\n",
    "unique, counts = np.unique(all_tags, return_counts=True)\n",
    "pd.DataFrame(unique, counts).sort_index(ascending=False)[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# multi binarize the tags\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([all_tags])\n",
    "\n",
    "print(mlb.classes_)\n",
    "\n",
    "# Test\n",
    "# one doc tags sample\n",
    "print(docs['Tags'][0])\n",
    "tags_mlb = mlb.transform([docs['Tags'][0].split()])\n",
    "print(tags_mlb)\n",
    "\n",
    "# previous multiclass binarizer is very huge, instead filter directly where indexes equals '1'\n",
    "for tag_index in np.where(tags_mlb == 1 )[1]:\n",
    "    print(f'{tag_index} : {mlb.classes_[tag_index]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags_count = pd.DataFrame({'tags': mlb.classes_})\n",
    "tags_count['count'] = \"\"\n",
    "tags_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, tag in enumerate(tags_count['tags']):\n",
    "    tags_count['count'].iloc[i] = all_tags.count(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags_count.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tags_count.sort_values('count', ascending=False)['count'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select only the tags that appear more than 100 times, thus reducing the number of tags to approx. 200\n",
    "# this produces our vocabulary for tagging\n",
    "currated_tags = tags_count[tags_count['count'] >= 100]['tags'].to_list()\n",
    "print(len(currated_tags))\n",
    "currated_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "long_string = ','.join(docs['Tags'])\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Words preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# WIP\n",
    "# how to remove unwanted chars in the question body ?\n",
    "import re\n",
    "\n",
    "zero = docs.iloc[0]\n",
    "re.sub('(<([^>]+)>)', '', zero.Body).replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remove code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs['Body'] = docs['Body'].apply(lambda d: d.replace('&lt;', '<').replace('&gt;', '>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_code_snippets(docs):\n",
    "    \"\"\"\n",
    "    Remove code snippets from docs\n",
    "    surrounded by <pre> tags\n",
    "    \"\"\"\n",
    "    # ensure '<' & '>' chars are set, not the unicode char\n",
    "    docs = docs.apply(lambda d: d.replace('&lt;', '<').replace('&gt;', '>'))\n",
    "    ret = []\n",
    "    for doc in docs:\n",
    "        soup = BeautifulSoup(doc, 'html.parser')\n",
    "        removals = soup.find_all('pre')\n",
    "        for pre in removals:\n",
    "            pre.decompose()\n",
    "        ret.append(soup.get_text())\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs['Body'] = remove_code_snippets(docs['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# words are the documents to use for the model\n",
    "# words = docs['Body'].to_list()\n",
    "words = docs['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remove Stop words, Lemmatize, Stemmize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "# lemmatize (convert and remove prefixes and suffixes to ignore the gender, plural, verb : walking, walks, walked, walk -> walk)\n",
    "# and/or stemmize (take the same root of words : universe / university -> univers)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stopwords.update(['p', 'gt', 'lt', 'li', 'ul', 'img', 'src', 'td', 'tr', 'table', 'div', 'code'])\n",
    "filtre_stopw =  lambda text: [token.lower() for token in text if token.lower() not in stopwords]\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import nltk\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "# tokenize and remove stop words\n",
    "def tokenize_sw_stem(doc):\n",
    "\t# nltk.word_tokenize(doc)\n",
    "    filtered = filtre_stopw(tokenizer.tokenize(doc))\n",
    "    ret = \" \".join([stemmer.stem(s) for s in filtered] )\n",
    "    return ret\n",
    "\n",
    "def tokenize_sw_lem(doc):\n",
    "    # nltk.word_tokenize(doc)\n",
    "    filtered = filtre_stopw(tokenizer.tokenize(doc))\n",
    "    ret = \" \".join([lemmatizer.lemmatize(s) for s in filtered] )\n",
    "    return ret\n",
    "\n",
    "\n",
    "words_stem = list(map(tokenize_sw_stem, words))\n",
    "words_lem = list(map(tokenize_sw_lem, words))\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words[543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_stem[543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_lem[543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's choose the lemmatize version of the corpus, since it results in real words that could be used as tags\n",
    "docs['currated_body'] = words_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs[['Body', 'currated_body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remove bad words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "re.sub(r'[0-9]+', '', words_lem[4733])\n",
    "# words tha contains underscores\n",
    "re.sub(r'_+', '', words_lem[4733])\n",
    "# words_lem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_words(words):\n",
    "    ret = []\n",
    "    for word in words:\n",
    "        # print(f'\\nprocessing sentence: {word}\\n')\n",
    "        flat = re.sub(r'[0-9]+', '', word) # words that are numbers\n",
    "        flat = re.sub(r'_+', '', flat) # words tha contains underscores\n",
    "        flat = re.sub(r'\\w{15,}', '', flat) # words longer than 15 chars are most probably code (i.e. myClass.myMethodName())\n",
    "        flat = \" \".join(flat.split()) # remove double spaces\n",
    "        # print(f'\\ncurrated : {flat}')\n",
    "        ret.append(flat)\n",
    "    return ret\n",
    "\n",
    "\n",
    "# re.sub(r'[0-9]*', '', words_lem[6543])\n",
    "# re.sub(r'_+', '', words_lem[6543])\n",
    "# currated = list(map(lambda x : re.sub(r'[0-9]*', '', x), words_lem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "currated = remove_words(words_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "currated[2649]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_lem[2649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs['currated_body'] = currated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs[['Body', 'currated_body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### MultiLabel Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# savoir quel est le nombre de tags max\n",
    "docs['tags_count'] = docs['Tags'].apply(lambda x : len(str(x).split())) # --> chaque docs à toujours 5 tags\n",
    "# faire une colonne du DF pour chaque tags\n",
    "docs[['tag0', 'tag1', 'tag2', 'tag3', 'tag4']] = docs['Tags'].str.split(expand=True)\n",
    "# donner les colonnes au mlb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "def mlb_tags(docs):\n",
    "    docs[['tag0', 'tag1', 'tag2', 'tag3', 'tag4']] = docs['Tags'].str.split(expand=True)\n",
    "    appended_tags = docs['Tags'].str.split(expand=True).stack()\n",
    "    light_tag_list = appended_tags.value_counts()[:200]\n",
    "    # fit the mlb with common tags (200)\n",
    "    mlb.fit([light_tag_list.index])\n",
    "    print(mlb.classes_.shape)\n",
    "    docs['mlb_tags'] = mlb.transform(docs[['tag0', 'tag1', 'tag2', 'tag3', 'tag4']].values).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# docs.drop('mlb_tags', axis=1, inplace=True)\n",
    "# docs.drop(['tag0', 'tag1', 'tag2', 'tag3', 'tag4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlb_tags(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Corpus size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count the total number of words in the overall corpus\n",
    "# needs to be limited to 2000 / 3000 words maximum\n",
    "lem = map(lambda x : x.split(), docs['currated_body'])\n",
    "flat_list = [word for sublist in list(lem) for word in sublist ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# if assertion fails, means we need to reduce the number of words \n",
    "# -> add the number of stop words\n",
    "unique_words = np.unique(flat_list)\n",
    "print(unique_words.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = docs.drop(columns='mlb_tags', axis=1)\n",
    "y = docs['mlb_tags']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tf-Idf BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X = vectorizer.fit_transform(docs['currated_body'])\n",
    "vectorizer.get_feature_names_out()\n",
    "print(X.shape)\n",
    "# X = pd.DataFrame(X.T.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('vectorizer', 'wb') as v :\n",
    "    pickle.dump(vectorizer, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def predict_tags(doc: str) -> list[str]:  \n",
    "    tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True,\n",
    "                            max_features = 3000, vocabulary = vectorizer.vocabulary_)\n",
    "    T = tf1_new.fit_transform(np.array([doc]))\n",
    "    T = pd.DataFrame(T.T.todense())\n",
    "    T[0].sort_values(ascending=False)\n",
    "    # take the 5 most interesting keywords\n",
    "    indexes = T[0].sort_values(ascending=False)[:5]\n",
    "    # print(indexes)\n",
    "    ret = []\n",
    "    for i, val in indexes.items():\n",
    "        # print(i)\n",
    "        # print(indexes[0].index[i])\n",
    "        if (val > 0): \n",
    "            ret.append(vectorizer.get_feature_names_out()[i])\n",
    "            # print(vectorizer.get_feature_names_out()[i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X = vectorizer.fit_transform(docs['currated_body'])\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "def get_top_tf_idf_words(response, top_n=2):\n",
    "    sorted_nzs = np.argsort(response.data)[:-(top_n+1):-1]\n",
    "    return feature_names[response.indices[sorted_nzs]]\n",
    "\n",
    "docs['tfidf_tags'] = [get_top_tf_idf_words(X, 5) for X in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# docs['Tags'].str.split(expand=True)\n",
    "docs['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs['tfidf_tags'].to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# [re.sub(r',', r' ', s) for s in str(docs['tfidf_tags'])]\n",
    "docs['tfidf_tags'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Multi-label scoring\n",
    "\n",
    "<https://medium.datadriveninvestor.com/predicting-tags-for-the-questions-in-stack-overflow-29438367261e>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# docs['predicted_tags'] = docs['currated_body'].apply(lambda row: predict_tags(row))\n",
    "docs['predicted_tags_idf_mlb'] = [mlb.transform(tags) for tags in docs['tfidf_tags']] \n",
    "\n",
    "\n",
    "\n",
    "# mlb.transform([predict_tags(docs['currated_body'].iloc[789])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 7541\n",
    "X = words_lem[index]\n",
    "y = docs['Tags'][index]\n",
    "predict = predict_tags(np.array(words_lem[index]))\n",
    "print(y.split())\n",
    "# print(X)\n",
    "print(predict)\n",
    "\n",
    "# count number of label predicted found from expected\n",
    "count = 0\n",
    "for tag in predict:\n",
    "    if tag in y.split():\n",
    "        # print(f'found tag correctly predicted: {tag}')\n",
    "        count += 1\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  compute the confusion matrix score for one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute multilabel binarizer for tags scoring\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "y_true = mlb.transform(y.split())\n",
    "y_pred = mlb.transform(predict)\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# confusion matrix MCM\n",
    "# MCM (0,0): TN\n",
    "# MCM (1,0): FN\n",
    "# MCM (1,1): TP\n",
    "# MCM (0,1): FP\n",
    "confusion_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "confusion_matrix[1602]\n",
    "\n",
    "np.where(mlb.classes_ == 'download')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample code to predict tags\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True,\n",
    "                          max_features = 5000, vocabulary = vectorizer.vocabulary_)\n",
    "T = tf1_new.fit_transform(np.array([\"configuring java for accessing database with jdbc is not working with JPA after upgrade of spring 5.1. despite having modified application.properties\"]))\n",
    "T = pd.DataFrame(T.T.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# T\n",
    "T[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# take the 3 most interesting keywords\n",
    "indexes = T[0].sort_values(ascending=False)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(indexes)\n",
    "for i, val in indexes.items():\n",
    "    # print(i)\n",
    "    # print(indexes[0].index[i])\n",
    "    if (val > 0): \n",
    "        print(vectorizer.get_feature_names_out()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# random index for testing\n",
    "doc_n = 543\n",
    "print(words[doc_n])\n",
    "sorted = X[doc_n].sort_values(ascending=False)[:15]\n",
    "print(sorted)\n",
    "print(vectorizer.get_feature_names_out()[sorted.index[0]]) #take the higher tf-idf value in the list, and get its corresponding word\n",
    "print(vectorizer.get_feature_names_out()[sorted.index[1]]) \n",
    "print(vectorizer.get_feature_names_out()[sorted.index[3]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs['Tags'][543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word2Vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# snippet taken from sample notebook\n",
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "w2v_epochs=100\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "w2v_model = gensim.models.Word2Vec(min_count=5, window=5,\n",
    "                                                vector_size=300,\n",
    "                                                seed=42,\n",
    "                                                # workers=30)\n",
    "                                               workers=multiprocessing.cpu_count())\n",
    "w2v_model.build_vocab(words_lem)\n",
    "w2v_model.train(words, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('w2v_model', 'wb') as v :\n",
    "    # pickle.dump(w2v_model, v)\n",
    "    w2v_model.save(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# word2vect docs and tutorial at https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "for index, word in enumerate(w2v_words):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(w2v_words)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "#  from https://www.kaggle.com/code/michaelfumery/stackoverflow-questions-tag-generator/notebook?scriptVersionId=68023262\n",
    "\n",
    "def metrics_score(model, df, y_true, y_pred):\n",
    "    \"\"\"Compilation function of metrics specific to multi-label\n",
    "    classification problems in a Pandas DataFrame.\n",
    "    This dataFrame will have 1 row per metric\n",
    "    and 1 column per model tested. \n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------\n",
    "    model : string\n",
    "        Name of the tested model\n",
    "    df : DataFrame \n",
    "        DataFrame to extend. \n",
    "        If None : Create DataFrame.\n",
    "    y_true : array\n",
    "        Array of true values to test\n",
    "    y_pred : array\n",
    "        Array of predicted values to test\n",
    "    ----------------------------------------\n",
    "    \"\"\"\n",
    "    if(df is not None):\n",
    "        temp_df = df\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\",\n",
    "                                      \"Jaccard\", \"Recall\",\n",
    "                                      \"Precision\"],\n",
    "                               columns=[model])\n",
    "        \n",
    "    scores = []\n",
    "    scores.append(metrics.accuracy_score(y_true, \n",
    "                                         y_pred))\n",
    "    scores.append(metrics.f1_score(y_pred, \n",
    "                                   y_true, \n",
    "                                   average='weighted'))\n",
    "    scores.append(metrics.jaccard_score(y_true, \n",
    "                                        y_pred, \n",
    "                                        average='weighted'))\n",
    "    scores.append(metrics.recall_score(y_true, \n",
    "                                       y_pred, \n",
    "                                       average='weighted'))\n",
    "    scores.append(metrics.precision_score(y_true, \n",
    "                                          y_pred, \n",
    "                                          average='weighted'))\n",
    "    temp_df[model] = scores\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "à lire\n",
    "\n",
    "\n",
    "topic modelling : unsupervised learning\n",
    "\n",
    "topic classification : supervised learning\n",
    "\n",
    "\n",
    "<https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n",
    "\n",
    "<https://www.baeldung.com/cs/ml-word2vec-topic-modeling>\n",
    "\n",
    "<https://medium.com/le-blog-de-lapprentissage-automatique/pr%C3%A9diction-des-tags-des-questions-de-stack-overflow-9be00f7672f9>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'javascript html angularjs angularjs-directive angularjs-ng-repeat'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['Tags'][543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word2Vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build & train Word2Vec model ...\n",
      "Vocabulary size: 64\n",
      "Word2Vec trained\n"
     ]
    }
   ],
   "source": [
    "# snippet taken from sample notebook\n",
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "w2v_epochs=100\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "w2v_model = gensim.models.Word2Vec(min_count=5, window=5,\n",
    "                                                vector_size=300,\n",
    "                                                seed=42,\n",
    "                                                # workers=30)\n",
    "                                               workers=multiprocessing.cpu_count())\n",
    "w2v_model.build_vocab(words_lem)\n",
    "w2v_model.train(words, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('w2v_model', 'wb') as v :\n",
    "    # pickle.dump(w2v_model, v)\n",
    "    w2v_model.save(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/290 is  \n",
      "word #1/290 is e\n",
      "word #2/290 is t\n",
      "word #3/290 is o\n",
      "word #4/290 is a\n",
      "word #5/290 is i\n",
      "word #6/290 is n\n",
      "word #7/290 is r\n",
      "word #8/290 is s\n",
      "word #9/290 is l\n"
     ]
    }
   ],
   "source": [
    "# word2vect docs and tutorial at https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "for index, word in enumerate(w2v_words):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(w2v_words)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "#  from https://www.kaggle.com/code/michaelfumery/stackoverflow-questions-tag-generator/notebook?scriptVersionId=68023262\n",
    "\n",
    "def metrics_score(model, df, y_true, y_pred):\n",
    "    \"\"\"Compilation function of metrics specific to multi-label\n",
    "    classification problems in a Pandas DataFrame.\n",
    "    This dataFrame will have 1 row per metric\n",
    "    and 1 column per model tested. \n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------\n",
    "    model : string\n",
    "        Name of the tested model\n",
    "    df : DataFrame \n",
    "        DataFrame to extend. \n",
    "        If None : Create DataFrame.\n",
    "    y_true : array\n",
    "        Array of true values to test\n",
    "    y_pred : array\n",
    "        Array of predicted values to test\n",
    "    ----------------------------------------\n",
    "    \"\"\"\n",
    "    if(df is not None):\n",
    "        temp_df = df\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\",\n",
    "                                      \"Jaccard\", \"Recall\",\n",
    "                                      \"Precision\"],\n",
    "                               columns=[model])\n",
    "        \n",
    "    scores = []\n",
    "    scores.append(metrics.accuracy_score(y_true, \n",
    "                                         y_pred))\n",
    "    scores.append(metrics.f1_score(y_pred, \n",
    "                                   y_true, \n",
    "                                   average='weighted'))\n",
    "    scores.append(metrics.jaccard_score(y_true, \n",
    "                                        y_pred, \n",
    "                                        average='weighted'))\n",
    "    scores.append(metrics.recall_score(y_true, \n",
    "                                       y_pred, \n",
    "                                       average='weighted'))\n",
    "    scores.append(metrics.precision_score(y_true, \n",
    "                                          y_pred, \n",
    "                                          average='weighted'))\n",
    "    temp_df[model] = scores\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "à lire\n",
    "\n",
    "\n",
    "topic modelling : unsupervised learning\n",
    "\n",
    "topic classification : supervised learning\n",
    "\n",
    "\n",
    "<https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n",
    "\n",
    "<https://www.baeldung.com/cs/ml-word2vec-topic-modeling>\n",
    "\n",
    "<https://medium.com/le-blog-de-lapprentissage-automatique/pr%C3%A9diction-des-tags-des-questions-de-stack-overflow-9be00f7672f9>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fab73fe7e639ca668fa1780ba818323dd4f7a1fb687fa2adeb62a663501d072"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
